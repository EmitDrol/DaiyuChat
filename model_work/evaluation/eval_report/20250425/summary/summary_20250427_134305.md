| dataset | version | metric | mode | Qwen2_5_7B |
|----- | ----- | ----- | ----- | -----|
| Language | - | - | - | - |
| race-high | - | - | - | - |
| ARC-c | - | - | - | - |
| BoolQ | - | - | - | - |
| triviaqa_wiki_1shot | - | - | - | - |
| nq_open_1shot | - | - | - | - |
| mmmlu_lite | - | - | - | - |
|  | - | - | - | - |
| Instruction Following | - | - | - | - |
| IFEval | - | - | - | - |
|  | - | - | - | - |
| General Reasoning | - | - | - | - |
| drop | - | - | - | - |
| bbeh | - | naive_average | gen | 9.88 |
| bbeh | - | harmonic_mean | gen | 2.77 |
| bbh | - | naive_average | gen | 59.34 |
| GPQA_diamond | - | - | - | - |
| hellaswag | 809ef1 | accuracy | gen | 76.97 |
| TheoremQA | - | - | - | - |
| musr_average | - | - | - | - |
| korbench_single | - | - | - | - |
| ARC_Prize_Public_Evaluation | - | - | - | - |
| hle_llmjudge | - | - | - | - |
| supergpqa | - | - | - | - |
|  | - | - | - | - |
| Math Calculation | - | - | - | - |
| gsm8k | - | - | - | - |
| GaokaoBench | - | - | - | - |
| math_prm800k_500-llmjudge | 6ff468 | accuracy | gen | 56.20 |
| cmo_fib | - | - | - | - |
| aime2024 | - | - | - | - |
| aime2025 | - | - | - | - |
| Mathbench | - | - | - | - |
|  | - | - | - | - |
| Knowledge | - | - | - | - |
| wikibench-wiki-single_choice_cncircular | - | - | - | - |
| cmmlu | - | accuracy | gen | 47.25 |
| mmlu | - | accuracy | gen | 71.38 |
| mmlu_pro | - | - | - | - |
|  | - | - | - | - |
| Code | - | - | - | - |
| openai_humaneval | - | - | - | - |
| sanitized_mbpp | - | - | - | - |
| humanevalx | - | - | - | - |
| ds1000 | - | - | - | - |
| lcb_code_generation_v4 | - | - | - | - |
| lcb_code_generation_v5 | - | - | - | - |
| bigcodebench_hard_instruct | - | - | - | - |
| bigcodebench_hard_complete | - | - | - | - |
|  | - | - | - | - |
| Agent | - | - | - | - |
| teval | - | - | - | - |
| SciCode | - | - | - | - |
| SciCode | - | - | - | - |
| qa_dingo_cn | - | - | - | - |
|  | - | - | - | - |
| supergpqa | - | - | - | - |
| supergpqa | - | - | - | - |
| supergpqa | - | - | - | - |
| supergpqa | - | - | - | - |
| supergpqa | - | - | - | - |
| supergpqa | - | - | - | - |
| supergpqa | - | - | - | - |
| supergpqa | - | - | - | - |
| supergpqa | - | - | - | - |
| supergpqa | - | - | - | - |
| supergpqa | - | - | - | - |
| supergpqa | - | - | - | - |
| supergpqa | - | - | - | - |
| supergpqa | - | - | - | - |
|  | - | - | - | - |
| mmlu | - | accuracy | gen | 71.38 |
| mmlu-stem | - | accuracy | gen | 69.02 |
| mmlu-social-science | - | accuracy | gen | 77.47 |
| mmlu-humanities | - | accuracy | gen | 69.74 |
| mmlu-other | - | accuracy | gen | 70.86 |
|  | - | - | - | - |
| cmmlu | - | accuracy | gen | 47.25 |
| cmmlu-stem | - | accuracy | gen | 43.54 |
| cmmlu-social-science | - | accuracy | gen | 45.82 |
| cmmlu-humanities | - | accuracy | gen | 54.49 |
| cmmlu-other | - | accuracy | gen | 47.24 |
| cmmlu-china-specific | - | accuracy | gen | 44.34 |
|  | - | - | - | - |
| mmlu_pro | - | - | - | - |
| mmlu_pro_biology | - | - | - | - |
| mmlu_pro_business | - | - | - | - |
| mmlu_pro_chemistry | - | - | - | - |
| mmlu_pro_computer_science | - | - | - | - |
| mmlu_pro_economics | - | - | - | - |
| mmlu_pro_engineering | - | - | - | - |
| mmlu_pro_health | - | - | - | - |
| mmlu_pro_history | - | - | - | - |
| mmlu_pro_law | - | - | - | - |
| mmlu_pro_math | - | - | - | - |
| mmlu_pro_philosophy | - | - | - | - |
| mmlu_pro_physics | - | - | - | - |
| mmlu_pro_psychology | - | - | - | - |
| mmlu_pro_other | - | - | - | - |
|  | - | - | - | - |
| humanevalx-python | - | - | - | - |
| humanevalx-cpp | - | - | - | - |
| humanevalx-go | - | - | - | - |
| humanevalx-java | - | - | - | - |
| humanevalx-js | - | - | - | - |
|  | - | - | - | - |
| ds1000_Pandas | - | - | - | - |
| ds1000_Numpy | - | - | - | - |
| ds1000_Tensorflow | - | - | - | - |
| ds1000_Scipy | - | - | - | - |
| ds1000_Sklearn | - | - | - | - |
| ds1000_Pytorch | - | - | - | - |
| ds1000_Matplotlib | - | - | - | - |
|  | - | - | - | - |
| mmmlu_lite | - | - | - | - |
| openai_mmmlu_lite_AR-XY | - | - | - | - |
| openai_mmmlu_lite_BN-BD | - | - | - | - |
| openai_mmmlu_lite_DE-DE | - | - | - | - |
| openai_mmmlu_lite_ES-LA | - | - | - | - |
| openai_mmmlu_lite_FR-FR | - | - | - | - |
| openai_mmmlu_lite_HI-IN | - | - | - | - |
| openai_mmmlu_lite_ID-ID | - | - | - | - |
| openai_mmmlu_lite_IT-IT | - | - | - | - |
| openai_mmmlu_lite_JA-JP | - | - | - | - |
| openai_mmmlu_lite_KO-KR | - | - | - | - |
| openai_mmmlu_lite_PT-BR | - | - | - | - |
| openai_mmmlu_lite_SW-KE | - | - | - | - |
| openai_mmmlu_lite_YO-NG | - | - | - | - |
| openai_mmmlu_lite_ZH-CN | - | - | - | - |
|  | - | - | - | - |
| ###### MathBench-A: Application Part ###### | - | - | - | - |
| college | - | - | - | - |
| high | - | - | - | - |
| middle | - | - | - | - |
| primary | - | - | - | - |
| arithmetic | - | - | - | - |
| mathbench-a (average) | - | - | - | - |
| ###### MathBench-T: Theory Part ###### | - | - | - | - |
| college_knowledge | - | - | - | - |
| high_knowledge | - | - | - | - |
| middle_knowledge | - | - | - | - |
| primary_knowledge | - | - | - | - |
| mathbench-t (average) | - | - | - | - |
