| dataset | version | metric | mode | Qwen2_5_7B | daiyu_20250423_183824 | Qwen2_5_7B-Instruct | daiyu_20250426_042114 |
|----- | ----- | ----- | ----- | ----- | ----- | ----- | -----|
| hellaswag | 809ef1 | accuracy | gen | - | 32.27 | 77.54 | 70.52 |
| hellaswag | 809ef1 | f1 | gen | - | 0.32 | 0.78 | 0.71 |
| math_prm800k_500-llmjudge | 6ff468 | accuracy | gen | - | 70.40 | 77.60 | 78.20 |
| math_prm800k_500-llmjudge | 6ff468 | f1 | gen | - | 0.70 | 0.78 | 0.78 |
| bbeh_boolean_expressions | ae90fc | accuracy | gen | - | 14.50 | 17.50 | 16.50 |
| bbeh_boolean_expressions | ae90fc | f1 | gen | - | 0.14 | 0.17 | 0.17 |
| bbeh_disambiguation_qa | ae90fc | accuracy | gen | - | 40.00 | 41.67 | 44.17 |
| bbeh_disambiguation_qa | ae90fc | f1 | gen | - | 0.40 | 0.42 | 0.44 |
| bbeh_geometric_shapes | ae90fc | accuracy | gen | - | 7.50 | 36.00 | 24.00 |
| bbeh_geometric_shapes | ae90fc | f1 | gen | - | 0.07 | 0.36 | 0.24 |
| bbeh_hyperbaton | ae90fc | accuracy | gen | - | 2.50 | 2.00 | 5.50 |
| bbeh_hyperbaton | ae90fc | f1 | gen | - | 0.03 | 0.02 | 0.06 |
| bbeh_movie_recommendation | ae90fc | accuracy | gen | - | 28.00 | 31.50 | 23.50 |
| bbeh_movie_recommendation | ae90fc | f1 | gen | - | 0.28 | 0.32 | 0.23 |
| bbeh_nycc | ae90fc | accuracy | gen | - | 7.50 | 8.50 | 11.00 |
| bbeh_nycc | ae90fc | f1 | gen | - | 0.07 | 0.09 | 0.11 |
| bbeh_shuffled_objects | ae90fc | accuracy | gen | - | 25.00 | 12.50 | 12.50 |
| bbeh_shuffled_objects | ae90fc | f1 | gen | - | 0.25 | 0.12 | 0.12 |
| bbeh_boardgame_qa | ae90fc | accuracy | gen | - | 30.50 | 30.50 | 34.50 |
| bbeh_boardgame_qa | ae90fc | f1 | gen | - | 0.30 | 0.30 | 0.34 |
| bbeh_buggy_tables | ae90fc | accuracy | gen | - | 2.00 | 1.50 | 1.50 |
| bbeh_buggy_tables | ae90fc | f1 | gen | - | 0.02 | 0.01 | 0.01 |
| bbeh_causal_understanding | ae90fc | accuracy | gen | - | 40.50 | 42.00 | 24.50 |
| bbeh_causal_understanding | ae90fc | f1 | gen | - | 0.41 | 0.42 | 0.24 |
| bbeh_dyck_languages | ae90fc | accuracy | gen | - | 0.50 | 1.00 | 0.50 |
| bbeh_dyck_languages | ae90fc | f1 | gen | - | 0.01 | 0.01 | 0.01 |
| bbeh_linguini | ae90fc | accuracy | gen | - | 5.50 | 6.00 | 5.00 |
| bbeh_linguini | ae90fc | f1 | gen | - | 0.06 | 0.06 | 0.05 |
| bbeh_multistep_arithmetic | ae90fc | accuracy | gen | - | 0.00 | 0.00 | 0.50 |
| bbeh_multistep_arithmetic | ae90fc | f1 | gen | - | 0.00 | 0.00 | 0.01 |
| bbeh_object_counting | ae90fc | accuracy | gen | - | 0.00 | 0.00 | 0.00 |
| bbeh_object_counting | ae90fc | f1 | gen | - | 0.00 | 0.00 | 0.00 |
| bbeh_object_properties | ae90fc | accuracy | gen | - | 4.00 | 0.50 | 0.00 |
| bbeh_object_properties | ae90fc | f1 | gen | - | 0.04 | 0.01 | 0.00 |
| bbeh_sarc_triples | ae90fc | accuracy | gen | - | 11.00 | 15.00 | 13.50 |
| bbeh_sarc_triples | ae90fc | f1 | gen | - | 0.11 | 0.15 | 0.14 |
| bbeh_spatial_reasoning | ae90fc | accuracy | gen | - | 15.00 | 0.50 | 0.00 |
| bbeh_spatial_reasoning | ae90fc | f1 | gen | - | 0.15 | 0.01 | 0.00 |
| bbeh_sportqa | ae90fc | accuracy | gen | - | 1.00 | 9.50 | 5.00 |
| bbeh_sportqa | ae90fc | f1 | gen | - | 0.01 | 0.10 | 0.05 |
| bbeh_temporal_sequence | ae90fc | accuracy | gen | - | 1.50 | 0.00 | 0.00 |
| bbeh_temporal_sequence | ae90fc | f1 | gen | - | 0.01 | 0.00 | 0.00 |
| bbeh_time_arithmetic | ae90fc | accuracy | gen | - | 14.00 | 20.00 | 20.00 |
| bbeh_time_arithmetic | ae90fc | f1 | gen | - | 0.14 | 0.20 | 0.20 |
| bbeh_web_of_lies | ae90fc | accuracy | gen | - | 9.00 | 3.50 | 4.00 |
| bbeh_web_of_lies | ae90fc | f1 | gen | - | 0.09 | 0.04 | 0.04 |
| bbeh_word_sorting | ae90fc | accuracy | gen | - | 1.50 | 1.50 | 2.50 |
| bbeh_word_sorting | ae90fc | f1 | gen | - | 0.01 | 0.01 | 0.03 |
| bbeh_zebra_puzzles | ae90fc | accuracy | gen | - | 18.00 | 17.00 | 16.50 |
| bbeh_zebra_puzzles | ae90fc | f1 | gen | - | 0.18 | 0.17 | 0.17 |
| bbh-temporal_sequences | 3f2d84 | score | gen | - | 46.40 | 74.00 | 77.20 |
| bbh-disambiguation_qa | 3f2d84 | score | gen | - | 64.80 | 51.60 | 46.40 |
| bbh-date_understanding | 3f2d84 | score | gen | - | 50.80 | 55.60 | 50.80 |
| bbh-tracking_shuffled_objects_three_objects | 3f2d84 | score | gen | - | 30.80 | 91.60 | 74.40 |
| bbh-penguins_in_a_table | 3f2d84 | score | gen | - | 78.77 | 89.73 | 70.55 |
| bbh-geometric_shapes | 3f2d84 | score | gen | - | 28.40 | 30.00 | 42.40 |
| bbh-snarks | 3f2d84 | score | gen | - | 75.28 | 76.40 | 75.84 |
| bbh-ruin_names | 3f2d84 | score | gen | - | 49.60 | 57.60 | 54.40 |
| bbh-tracking_shuffled_objects_seven_objects | 3f2d84 | score | gen | - | 39.60 | 80.40 | 54.80 |
| bbh-tracking_shuffled_objects_five_objects | 3f2d84 | score | gen | - | 52.40 | 89.20 | 78.00 |
| bbh-logical_deduction_three_objects | 3f2d84 | score | gen | - | 73.60 | 74.40 | 72.00 |
| bbh-hyperbaton | 3f2d84 | score | gen | - | 83.60 | 60.40 | 67.20 |
| bbh-logical_deduction_five_objects | 3f2d84 | score | gen | - | 44.80 | 62.40 | 56.00 |
| bbh-logical_deduction_seven_objects | 3f2d84 | score | gen | - | 44.80 | 52.80 | 48.40 |
| bbh-movie_recommendation | 3f2d84 | score | gen | - | 65.20 | 64.00 | 60.00 |
| bbh-salient_translation_error_detection | 3f2d84 | score | gen | - | 36.00 | 43.20 | 43.60 |
| bbh-reasoning_about_colored_objects | 3f2d84 | score | gen | - | 70.80 | 77.20 | 60.80 |
| bbh-multistep_arithmetic_two | 3f2d84 | score | gen | - | 82.00 | 87.60 | 81.60 |
| bbh-navigate | 3f2d84 | score | gen | - | 59.20 | 63.20 | 59.60 |
| bbh-dyck_languages | 3f2d84 | score | gen | - | 2.40 | 0.80 | 2.00 |
| bbh-word_sorting | 3f2d84 | score | gen | - | 25.60 | 20.40 | 24.80 |
| bbh-sports_understanding | 3f2d84 | score | gen | - | 69.20 | 66.00 | 55.60 |
| bbh-boolean_expressions | 3f2d84 | score | gen | - | 84.00 | 79.60 | 79.60 |
| bbh-object_counting | 3f2d84 | score | gen | - | 64.00 | 46.00 | 50.40 |
| bbh-formal_fallacies | 3f2d84 | score | gen | - | 57.20 | 60.40 | 58.40 |
| bbh-causal_judgement | 3f2d84 | score | gen | - | 56.68 | 54.55 | 52.94 |
| bbh-web_of_lies | 3f2d84 | score | gen | - | 66.40 | 90.80 | 70.40 |
| cmmlu-agronomy | 7c9e30 | accuracy | gen | - | 31.36 | 69.82 | 68.05 |
| cmmlu-agronomy | 7c9e30 | f1 | gen | - | 0.31 | 0.70 | 0.68 |
| cmmlu-anatomy | 84ab0f | accuracy | gen | - | 28.38 | 85.81 | 87.16 |
| cmmlu-anatomy | 84ab0f | f1 | gen | - | 0.28 | 0.86 | 0.87 |
| cmmlu-ancient_chinese | 18a73e | accuracy | gen | - | 4.27 | 45.73 | 46.95 |
| cmmlu-ancient_chinese | 18a73e | f1 | gen | - | 0.04 | 0.46 | 0.47 |
| cmmlu-arts | d496c2 | accuracy | gen | - | 38.12 | 96.25 | 93.75 |
| cmmlu-arts | d496c2 | f1 | gen | - | 0.38 | 0.96 | 0.94 |
| cmmlu-astronomy | 94a1ad | accuracy | gen | - | 27.27 | 56.36 | 51.52 |
| cmmlu-astronomy | 94a1ad | f1 | gen | - | 0.27 | 0.56 | 0.52 |
| cmmlu-business_ethics | b66299 | accuracy | gen | - | 26.79 | 66.99 | 68.42 |
| cmmlu-business_ethics | b66299 | f1 | gen | - | 0.27 | 0.67 | 0.68 |
| cmmlu-chinese_civil_service_exam | 41629d | accuracy | gen | - | 25.00 | 70.62 | 76.25 |
| cmmlu-chinese_civil_service_exam | 41629d | f1 | gen | - | 0.25 | 0.71 | 0.76 |
| cmmlu-chinese_driving_rule | 1e9d3c | accuracy | gen | - | 35.88 | 96.18 | 96.95 |
| cmmlu-chinese_driving_rule | 1e9d3c | f1 | gen | - | 0.36 | 0.96 | 0.97 |
| cmmlu-chinese_food_culture | 5fe533 | accuracy | gen | - | 25.00 | 72.06 | 73.53 |
| cmmlu-chinese_food_culture | 5fe533 | f1 | gen | - | 0.25 | 0.72 | 0.74 |
| cmmlu-chinese_foreign_policy | 50ea53 | accuracy | gen | - | 37.38 | 73.83 | 75.70 |
| cmmlu-chinese_foreign_policy | 50ea53 | f1 | gen | - | 0.37 | 0.74 | 0.76 |
| cmmlu-chinese_history | 65d9e7 | accuracy | gen | - | 34.67 | 82.97 | 86.07 |
| cmmlu-chinese_history | 65d9e7 | f1 | gen | - | 0.35 | 0.83 | 0.86 |
| cmmlu-chinese_literature | bf10c3 | accuracy | gen | - | 10.78 | 66.18 | 69.12 |
| cmmlu-chinese_literature | bf10c3 | f1 | gen | - | 0.11 | 0.66 | 0.69 |
| cmmlu-chinese_teacher_qualification | 0fc6aa | accuracy | gen | - | 30.73 | 89.39 | 89.94 |
| cmmlu-chinese_teacher_qualification | 0fc6aa | f1 | gen | - | 0.31 | 0.89 | 0.90 |
| cmmlu-clinical_knowledge | e8fd9f | accuracy | gen | - | 32.07 | 75.53 | 77.64 |
| cmmlu-clinical_knowledge | e8fd9f | f1 | gen | - | 0.32 | 0.76 | 0.78 |
| cmmlu-college_actuarial_science | c0c119 | accuracy | gen | - | 9.43 | 45.28 | 43.40 |
| cmmlu-college_actuarial_science | c0c119 | f1 | gen | - | 0.09 | 0.45 | 0.43 |
| cmmlu-college_education | a6d967 | accuracy | gen | - | 37.38 | 83.18 | 87.85 |
| cmmlu-college_education | a6d967 | f1 | gen | - | 0.37 | 0.83 | 0.88 |
| cmmlu-college_engineering_hydrology | 2fc1c4 | accuracy | gen | - | 45.28 | 82.08 | 78.30 |
| cmmlu-college_engineering_hydrology | 2fc1c4 | f1 | gen | - | 0.45 | 0.82 | 0.78 |
| cmmlu-college_law | d918f6 | accuracy | gen | - | 26.85 | 68.52 | 67.59 |
| cmmlu-college_law | d918f6 | f1 | gen | - | 0.27 | 0.69 | 0.68 |
| cmmlu-college_mathematics | b665a2 | accuracy | gen | - | 28.57 | 58.10 | 43.81 |
| cmmlu-college_mathematics | b665a2 | f1 | gen | - | 0.29 | 0.58 | 0.44 |
| cmmlu-college_medical_statistics | 2b1a51 | accuracy | gen | - | 23.58 | 69.81 | 70.75 |
| cmmlu-college_medical_statistics | 2b1a51 | f1 | gen | - | 0.24 | 0.70 | 0.71 |
| cmmlu-college_medicine | ac9e75 | accuracy | gen | - | 30.04 | 83.52 | 83.52 |
| cmmlu-college_medicine | ac9e75 | f1 | gen | - | 0.30 | 0.84 | 0.84 |
| cmmlu-computer_science | 5b63b8 | accuracy | gen | - | 24.51 | 86.27 | 84.31 |
| cmmlu-computer_science | 5b63b8 | f1 | gen | - | 0.25 | 0.86 | 0.84 |
| cmmlu-computer_security | c37854 | accuracy | gen | - | 26.32 | 87.72 | 88.30 |
| cmmlu-computer_security | c37854 | f1 | gen | - | 0.26 | 0.88 | 0.88 |
| cmmlu-conceptual_physics | e13116 | accuracy | gen | - | 30.61 | 89.12 | 87.07 |
| cmmlu-conceptual_physics | e13116 | f1 | gen | - | 0.31 | 0.89 | 0.87 |
| cmmlu-construction_project_management | 799df1 | accuracy | gen | - | 19.42 | 68.35 | 69.78 |
| cmmlu-construction_project_management | 799df1 | f1 | gen | - | 0.19 | 0.68 | 0.70 |
| cmmlu-economics | 503c58 | accuracy | gen | - | 49.69 | 83.65 | 81.13 |
| cmmlu-economics | 503c58 | f1 | gen | - | 0.50 | 0.84 | 0.81 |
| cmmlu-education | 823c96 | accuracy | gen | - | 26.38 | 77.30 | 76.07 |
| cmmlu-education | 823c96 | f1 | gen | - | 0.26 | 0.77 | 0.76 |
| cmmlu-electrical_engineering | 69c4f3 | accuracy | gen | - | 34.88 | 81.40 | 81.98 |
| cmmlu-electrical_engineering | 69c4f3 | f1 | gen | - | 0.35 | 0.81 | 0.82 |
| cmmlu-elementary_chinese | 61ed08 | accuracy | gen | - | 29.37 | 76.19 | 75.40 |
| cmmlu-elementary_chinese | 61ed08 | f1 | gen | - | 0.29 | 0.76 | 0.75 |
| cmmlu-elementary_commonsense | 3c2aa7 | accuracy | gen | - | 24.24 | 78.79 | 74.24 |
| cmmlu-elementary_commonsense | 3c2aa7 | f1 | gen | - | 0.24 | 0.79 | 0.74 |
| cmmlu-elementary_information_and_technology | 4ba53f | accuracy | gen | - | 31.51 | 94.54 | 94.54 |
| cmmlu-elementary_information_and_technology | 4ba53f | f1 | gen | - | 0.32 | 0.95 | 0.95 |
| cmmlu-elementary_mathematics | 1fe0ee | accuracy | gen | - | 40.00 | 80.87 | 70.87 |
| cmmlu-elementary_mathematics | 1fe0ee | f1 | gen | - | 0.40 | 0.81 | 0.71 |
| cmmlu-ethnology | ae0ac8 | accuracy | gen | - | 31.85 | 76.30 | 77.04 |
| cmmlu-ethnology | ae0ac8 | f1 | gen | - | 0.32 | 0.76 | 0.77 |
| cmmlu-food_science | dfb5a1 | accuracy | gen | - | 21.68 | 73.43 | 69.93 |
| cmmlu-food_science | dfb5a1 | f1 | gen | - | 0.22 | 0.73 | 0.70 |
| cmmlu-genetics | 95a0c9 | accuracy | gen | - | 26.70 | 69.32 | 66.48 |
| cmmlu-genetics | 95a0c9 | f1 | gen | - | 0.27 | 0.69 | 0.66 |
| cmmlu-global_facts | e3cf9e | accuracy | gen | - | 24.83 | 78.52 | 78.52 |
| cmmlu-global_facts | e3cf9e | f1 | gen | - | 0.25 | 0.79 | 0.79 |
| cmmlu-high_school_biology | 0811e7 | accuracy | gen | - | 13.02 | 82.25 | 82.25 |
| cmmlu-high_school_biology | 0811e7 | f1 | gen | - | 0.13 | 0.82 | 0.82 |
| cmmlu-high_school_chemistry | 342b0f | accuracy | gen | - | 3.03 | 65.91 | 68.18 |
| cmmlu-high_school_chemistry | 342b0f | f1 | gen | - | 0.03 | 0.66 | 0.68 |
| cmmlu-high_school_geography | 2a2c92 | accuracy | gen | - | 42.37 | 77.97 | 79.66 |
| cmmlu-high_school_geography | 2a2c92 | f1 | gen | - | 0.42 | 0.78 | 0.80 |
| cmmlu-high_school_mathematics | 86f22a | accuracy | gen | - | 39.63 | 79.88 | 70.12 |
| cmmlu-high_school_mathematics | 86f22a | f1 | gen | - | 0.40 | 0.80 | 0.70 |
| cmmlu-high_school_physics | d4fe4b | accuracy | gen | - | 29.09 | 75.45 | 77.27 |
| cmmlu-high_school_physics | d4fe4b | f1 | gen | - | 0.29 | 0.75 | 0.77 |
| cmmlu-high_school_politics | ded656 | accuracy | gen | - | 30.77 | 82.52 | 86.01 |
| cmmlu-high_school_politics | ded656 | f1 | gen | - | 0.31 | 0.83 | 0.86 |
| cmmlu-human_sexuality | 11cfc3 | accuracy | gen | - | 15.87 | 71.43 | 66.67 |
| cmmlu-human_sexuality | 11cfc3 | f1 | gen | - | 0.16 | 0.71 | 0.67 |
| cmmlu-international_law | 0bc7f3 | accuracy | gen | - | 27.57 | 73.51 | 71.89 |
| cmmlu-international_law | 0bc7f3 | f1 | gen | - | 0.28 | 0.74 | 0.72 |
| cmmlu-journalism | 9b0da8 | accuracy | gen | - | 27.91 | 72.09 | 76.74 |
| cmmlu-journalism | 9b0da8 | f1 | gen | - | 0.28 | 0.72 | 0.77 |
| cmmlu-jurisprudence | 63bbe5 | accuracy | gen | - | 27.98 | 81.51 | 82.00 |
| cmmlu-jurisprudence | 63bbe5 | f1 | gen | - | 0.28 | 0.82 | 0.82 |
| cmmlu-legal_and_moral_basis | 252a51 | accuracy | gen | - | 32.24 | 97.20 | 97.66 |
| cmmlu-legal_and_moral_basis | 252a51 | f1 | gen | - | 0.32 | 0.97 | 0.98 |
| cmmlu-logical | 245f3d | accuracy | gen | - | 27.64 | 72.36 | 73.98 |
| cmmlu-logical | 245f3d | f1 | gen | - | 0.28 | 0.72 | 0.74 |
| cmmlu-machine_learning | 1992ee | accuracy | gen | - | 31.15 | 71.31 | 72.95 |
| cmmlu-machine_learning | 1992ee | f1 | gen | - | 0.31 | 0.71 | 0.73 |
| cmmlu-management | 454dc0 | accuracy | gen | - | 38.10 | 86.19 | 84.29 |
| cmmlu-management | 454dc0 | f1 | gen | - | 0.38 | 0.86 | 0.84 |
| cmmlu-marketing | cb3955 | accuracy | gen | - | 32.22 | 85.56 | 84.44 |
| cmmlu-marketing | cb3955 | f1 | gen | - | 0.32 | 0.86 | 0.84 |
| cmmlu-marxist_theory | 88f9a2 | accuracy | gen | - | 55.56 | 93.12 | 93.65 |
| cmmlu-marxist_theory | 88f9a2 | f1 | gen | - | 0.56 | 0.93 | 0.94 |
| cmmlu-modern_chinese | 84adbd | accuracy | gen | - | 9.48 | 62.07 | 58.62 |
| cmmlu-modern_chinese | 84adbd | f1 | gen | - | 0.09 | 0.62 | 0.59 |
| cmmlu-nutrition | 157fb8 | accuracy | gen | - | 27.59 | 78.62 | 78.62 |
| cmmlu-nutrition | 157fb8 | f1 | gen | - | 0.28 | 0.79 | 0.79 |
| cmmlu-philosophy | cbe293 | accuracy | gen | - | 39.05 | 77.14 | 77.14 |
| cmmlu-philosophy | cbe293 | f1 | gen | - | 0.39 | 0.77 | 0.77 |
| cmmlu-professional_accounting | 1fd7d6 | accuracy | gen | - | 45.71 | 90.86 | 88.57 |
| cmmlu-professional_accounting | 1fd7d6 | f1 | gen | - | 0.46 | 0.91 | 0.89 |
| cmmlu-professional_law | b24c17 | accuracy | gen | - | 26.54 | 73.93 | 72.04 |
| cmmlu-professional_law | b24c17 | f1 | gen | - | 0.27 | 0.74 | 0.72 |
| cmmlu-professional_medicine | 8780af | accuracy | gen | - | 28.72 | 77.39 | 76.33 |
| cmmlu-professional_medicine | 8780af | f1 | gen | - | 0.29 | 0.77 | 0.76 |
| cmmlu-professional_psychology | 312211 | accuracy | gen | - | 33.62 | 84.48 | 85.34 |
| cmmlu-professional_psychology | 312211 | f1 | gen | - | 0.34 | 0.84 | 0.85 |
| cmmlu-public_relations | 108236 | accuracy | gen | - | 18.39 | 70.11 | 71.84 |
| cmmlu-public_relations | 108236 | f1 | gen | - | 0.18 | 0.70 | 0.72 |
| cmmlu-security_study | 4ae05c | accuracy | gen | - | 36.30 | 85.93 | 88.89 |
| cmmlu-security_study | 4ae05c | f1 | gen | - | 0.36 | 0.86 | 0.89 |
| cmmlu-sociology | e243f7 | accuracy | gen | - | 32.30 | 78.32 | 75.66 |
| cmmlu-sociology | e243f7 | f1 | gen | - | 0.32 | 0.78 | 0.76 |
| cmmlu-sports_science | 591cca | accuracy | gen | - | 22.42 | 72.73 | 75.15 |
| cmmlu-sports_science | 591cca | f1 | gen | - | 0.22 | 0.73 | 0.75 |
| cmmlu-traditional_chinese_medicine | 427690 | accuracy | gen | - | 39.46 | 78.92 | 79.46 |
| cmmlu-traditional_chinese_medicine | 427690 | f1 | gen | - | 0.39 | 0.79 | 0.79 |
| cmmlu-virology | 708dbd | accuracy | gen | - | 27.22 | 79.88 | 79.29 |
| cmmlu-virology | 708dbd | f1 | gen | - | 0.27 | 0.80 | 0.79 |
| cmmlu-world_history | 18602e | accuracy | gen | - | 43.48 | 78.88 | 83.23 |
| cmmlu-world_history | 18602e | f1 | gen | - | 0.43 | 0.79 | 0.83 |
| cmmlu-world_religions | a38f01 | accuracy | gen | - | 18.75 | 83.75 | 80.62 |
| cmmlu-world_religions | a38f01 | f1 | gen | - | 0.19 | 0.84 | 0.81 |
| lukaemon_mmlu_college_biology | 012dd1 | accuracy | gen | - | 84.03 | 81.25 | 84.03 |
| lukaemon_mmlu_college_biology | 012dd1 | f1 | gen | - | 0.84 | 0.81 | 0.84 |
| lukaemon_mmlu_college_chemistry | 012dd1 | accuracy | gen | - | 51.00 | 55.00 | 54.00 |
| lukaemon_mmlu_college_chemistry | 012dd1 | f1 | gen | - | 0.51 | 0.55 | 0.54 |
| lukaemon_mmlu_college_computer_science | 012dd1 | accuracy | gen | - | 71.00 | 80.00 | 77.00 |
| lukaemon_mmlu_college_computer_science | 012dd1 | f1 | gen | - | 0.71 | 0.80 | 0.77 |
| lukaemon_mmlu_college_mathematics | 012dd1 | accuracy | gen | - | 63.00 | 73.00 | 70.00 |
| lukaemon_mmlu_college_mathematics | 012dd1 | f1 | gen | - | 0.63 | 0.73 | 0.70 |
| lukaemon_mmlu_college_physics | 012dd1 | accuracy | gen | - | 73.53 | 78.43 | 78.43 |
| lukaemon_mmlu_college_physics | 012dd1 | f1 | gen | - | 0.74 | 0.78 | 0.78 |
| lukaemon_mmlu_electrical_engineering | 012dd1 | accuracy | gen | - | 68.97 | 67.59 | 65.52 |
| lukaemon_mmlu_electrical_engineering | 012dd1 | f1 | gen | - | 0.69 | 0.68 | 0.66 |
| lukaemon_mmlu_astronomy | 012dd1 | accuracy | gen | - | 75.66 | 81.58 | 83.55 |
| lukaemon_mmlu_astronomy | 012dd1 | f1 | gen | - | 0.76 | 0.82 | 0.84 |
| lukaemon_mmlu_anatomy | 012dd1 | accuracy | gen | - | 71.11 | 74.07 | 66.67 |
| lukaemon_mmlu_anatomy | 012dd1 | f1 | gen | - | 0.71 | 0.74 | 0.67 |
| lukaemon_mmlu_abstract_algebra | 012dd1 | accuracy | gen | - | 58.00 | 68.00 | 72.00 |
| lukaemon_mmlu_abstract_algebra | 012dd1 | f1 | gen | - | 0.58 | 0.68 | 0.72 |
| lukaemon_mmlu_machine_learning | 012dd1 | accuracy | gen | - | 58.04 | 57.14 | 62.50 |
| lukaemon_mmlu_machine_learning | 012dd1 | f1 | gen | - | 0.58 | 0.57 | 0.62 |
| lukaemon_mmlu_clinical_knowledge | 012dd1 | accuracy | gen | - | 72.45 | 77.36 | 77.74 |
| lukaemon_mmlu_clinical_knowledge | 012dd1 | f1 | gen | - | 0.72 | 0.77 | 0.78 |
| lukaemon_mmlu_global_facts | 012dd1 | accuracy | gen | - | 50.00 | 44.00 | 49.00 |
| lukaemon_mmlu_global_facts | 012dd1 | f1 | gen | - | 0.50 | 0.44 | 0.49 |
| lukaemon_mmlu_management | 012dd1 | accuracy | gen | - | 82.52 | 79.61 | 83.50 |
| lukaemon_mmlu_management | 012dd1 | f1 | gen | - | 0.83 | 0.80 | 0.83 |
| lukaemon_mmlu_nutrition | 012dd1 | accuracy | gen | - | 70.92 | 78.76 | 79.08 |
| lukaemon_mmlu_nutrition | 012dd1 | f1 | gen | - | 0.71 | 0.79 | 0.79 |
| lukaemon_mmlu_marketing | 012dd1 | accuracy | gen | - | 85.04 | 83.76 | 87.61 |
| lukaemon_mmlu_marketing | 012dd1 | f1 | gen | - | 0.85 | 0.84 | 0.88 |
| lukaemon_mmlu_professional_accounting | 012dd1 | accuracy | gen | - | 59.22 | 64.89 | 66.67 |
| lukaemon_mmlu_professional_accounting | 012dd1 | f1 | gen | - | 0.59 | 0.65 | 0.67 |
| lukaemon_mmlu_high_school_geography | 012dd1 | accuracy | gen | - | 82.83 | 83.33 | 84.34 |
| lukaemon_mmlu_high_school_geography | 012dd1 | f1 | gen | - | 0.83 | 0.83 | 0.84 |
| lukaemon_mmlu_international_law | 012dd1 | accuracy | gen | - | 79.34 | 76.86 | 80.17 |
| lukaemon_mmlu_international_law | 012dd1 | f1 | gen | - | 0.79 | 0.77 | 0.80 |
| lukaemon_mmlu_moral_scenarios | 012dd1 | accuracy | gen | - | 42.35 | 42.68 | 47.37 |
| lukaemon_mmlu_moral_scenarios | 012dd1 | f1 | gen | - | 0.42 | 0.43 | 0.47 |
| lukaemon_mmlu_computer_security | 012dd1 | accuracy | gen | - | 76.00 | 76.00 | 80.00 |
| lukaemon_mmlu_computer_security | 012dd1 | f1 | gen | - | 0.76 | 0.76 | 0.80 |
| lukaemon_mmlu_high_school_microeconomics | 012dd1 | accuracy | gen | - | 84.87 | 81.93 | 84.03 |
| lukaemon_mmlu_high_school_microeconomics | 012dd1 | f1 | gen | - | 0.85 | 0.82 | 0.84 |
| lukaemon_mmlu_professional_law | 012dd1 | accuracy | gen | - | 47.39 | 50.13 | 50.33 |
| lukaemon_mmlu_professional_law | 012dd1 | f1 | gen | - | 0.47 | 0.50 | 0.50 |
| lukaemon_mmlu_medical_genetics | 012dd1 | accuracy | gen | - | 75.00 | 80.00 | 89.00 |
| lukaemon_mmlu_medical_genetics | 012dd1 | f1 | gen | - | 0.75 | 0.80 | 0.89 |
| lukaemon_mmlu_professional_psychology | 012dd1 | accuracy | gen | - | 71.24 | 72.06 | 73.86 |
| lukaemon_mmlu_professional_psychology | 012dd1 | f1 | gen | - | 0.71 | 0.72 | 0.74 |
| lukaemon_mmlu_jurisprudence | 012dd1 | accuracy | gen | - | 78.70 | 68.52 | 77.78 |
| lukaemon_mmlu_jurisprudence | 012dd1 | f1 | gen | - | 0.79 | 0.69 | 0.78 |
| lukaemon_mmlu_world_religions | 012dd1 | accuracy | gen | - | 83.04 | 83.04 | 83.63 |
| lukaemon_mmlu_world_religions | 012dd1 | f1 | gen | - | 0.83 | 0.83 | 0.84 |
| lukaemon_mmlu_philosophy | 012dd1 | accuracy | gen | - | 69.77 | 69.45 | 70.10 |
| lukaemon_mmlu_philosophy | 012dd1 | f1 | gen | - | 0.70 | 0.69 | 0.70 |
| lukaemon_mmlu_virology | 012dd1 | accuracy | gen | - | 47.59 | 50.00 | 50.60 |
| lukaemon_mmlu_virology | 012dd1 | f1 | gen | - | 0.48 | 0.50 | 0.51 |
| lukaemon_mmlu_high_school_chemistry | 012dd1 | accuracy | gen | - | 68.47 | 69.95 | 73.89 |
| lukaemon_mmlu_high_school_chemistry | 012dd1 | f1 | gen | - | 0.68 | 0.70 | 0.74 |
| lukaemon_mmlu_public_relations | 012dd1 | accuracy | gen | - | 63.64 | 64.55 | 65.45 |
| lukaemon_mmlu_public_relations | 012dd1 | f1 | gen | - | 0.64 | 0.65 | 0.65 |
| lukaemon_mmlu_high_school_macroeconomics | 012dd1 | accuracy | gen | - | 74.62 | 78.46 | 82.31 |
| lukaemon_mmlu_high_school_macroeconomics | 012dd1 | f1 | gen | - | 0.75 | 0.78 | 0.82 |
| lukaemon_mmlu_human_sexuality | 012dd1 | accuracy | gen | - | 74.05 | 77.10 | 76.34 |
| lukaemon_mmlu_human_sexuality | 012dd1 | f1 | gen | - | 0.74 | 0.77 | 0.76 |
| lukaemon_mmlu_elementary_mathematics | 012dd1 | accuracy | gen | - | 91.80 | 95.24 | 94.44 |
| lukaemon_mmlu_elementary_mathematics | 012dd1 | f1 | gen | - | 0.92 | 0.95 | 0.94 |
| lukaemon_mmlu_high_school_physics | 012dd1 | accuracy | gen | - | 70.20 | 70.20 | 73.51 |
| lukaemon_mmlu_high_school_physics | 012dd1 | f1 | gen | - | 0.70 | 0.70 | 0.74 |
| lukaemon_mmlu_high_school_computer_science | 012dd1 | accuracy | gen | - | 86.00 | 85.00 | 90.00 |
| lukaemon_mmlu_high_school_computer_science | 012dd1 | f1 | gen | - | 0.86 | 0.85 | 0.90 |
| lukaemon_mmlu_high_school_european_history | 012dd1 | accuracy | gen | - | 72.12 | 81.21 | 80.00 |
| lukaemon_mmlu_high_school_european_history | 012dd1 | f1 | gen | - | 0.72 | 0.81 | 0.80 |
| lukaemon_mmlu_business_ethics | 012dd1 | accuracy | gen | - | 73.00 | 63.00 | 67.00 |
| lukaemon_mmlu_business_ethics | 012dd1 | f1 | gen | - | 0.73 | 0.63 | 0.67 |
| lukaemon_mmlu_moral_disputes | 012dd1 | accuracy | gen | - | 67.34 | 67.92 | 70.81 |
| lukaemon_mmlu_moral_disputes | 012dd1 | f1 | gen | - | 0.67 | 0.68 | 0.71 |
| lukaemon_mmlu_high_school_statistics | 012dd1 | accuracy | gen | - | 75.93 | 80.56 | 84.26 |
| lukaemon_mmlu_high_school_statistics | 012dd1 | f1 | gen | - | 0.76 | 0.81 | 0.84 |
| lukaemon_mmlu_miscellaneous | 012dd1 | accuracy | gen | - | 84.16 | 84.55 | 86.85 |
| lukaemon_mmlu_miscellaneous | 012dd1 | f1 | gen | - | 0.84 | 0.85 | 0.87 |
| lukaemon_mmlu_formal_logic | 012dd1 | accuracy | gen | - | 53.17 | 53.17 | 57.94 |
| lukaemon_mmlu_formal_logic | 012dd1 | f1 | gen | - | 0.53 | 0.53 | 0.58 |
| lukaemon_mmlu_high_school_government_and_politics | 012dd1 | accuracy | gen | - | 88.08 | 89.12 | 90.16 |
| lukaemon_mmlu_high_school_government_and_politics | 012dd1 | f1 | gen | - | 0.88 | 0.89 | 0.90 |
| lukaemon_mmlu_prehistory | 012dd1 | accuracy | gen | - | 74.38 | 77.78 | 78.40 |
| lukaemon_mmlu_prehistory | 012dd1 | f1 | gen | - | 0.74 | 0.78 | 0.78 |
| lukaemon_mmlu_security_studies | 012dd1 | accuracy | gen | - | 64.90 | 70.61 | 73.06 |
| lukaemon_mmlu_security_studies | 012dd1 | f1 | gen | - | 0.65 | 0.71 | 0.73 |
| lukaemon_mmlu_high_school_biology | 012dd1 | accuracy | gen | - | 83.55 | 85.48 | 84.19 |
| lukaemon_mmlu_high_school_biology | 012dd1 | f1 | gen | - | 0.84 | 0.85 | 0.84 |
| lukaemon_mmlu_logical_fallacies | 012dd1 | accuracy | gen | - | 76.07 | 77.30 | 76.07 |
| lukaemon_mmlu_logical_fallacies | 012dd1 | f1 | gen | - | 0.76 | 0.77 | 0.76 |
| lukaemon_mmlu_high_school_world_history | 012dd1 | accuracy | gen | - | 78.90 | 84.81 | 78.90 |
| lukaemon_mmlu_high_school_world_history | 012dd1 | f1 | gen | - | 0.79 | 0.85 | 0.79 |
| lukaemon_mmlu_professional_medicine | 012dd1 | accuracy | gen | - | 75.74 | 76.84 | 76.84 |
| lukaemon_mmlu_professional_medicine | 012dd1 | f1 | gen | - | 0.76 | 0.77 | 0.77 |
| lukaemon_mmlu_high_school_mathematics | 012dd1 | accuracy | gen | - | 81.48 | 88.52 | 88.52 |
| lukaemon_mmlu_high_school_mathematics | 012dd1 | f1 | gen | - | 0.81 | 0.89 | 0.89 |
| lukaemon_mmlu_college_medicine | 012dd1 | accuracy | gen | - | 64.16 | 68.79 | 71.10 |
| lukaemon_mmlu_college_medicine | 012dd1 | f1 | gen | - | 0.64 | 0.69 | 0.71 |
| lukaemon_mmlu_high_school_us_history | 012dd1 | accuracy | gen | - | 75.98 | 85.78 | 83.33 |
| lukaemon_mmlu_high_school_us_history | 012dd1 | f1 | gen | - | 0.76 | 0.86 | 0.83 |
| lukaemon_mmlu_sociology | 012dd1 | accuracy | gen | - | 85.57 | 77.61 | 83.08 |
| lukaemon_mmlu_sociology | 012dd1 | f1 | gen | - | 0.86 | 0.78 | 0.83 |
| lukaemon_mmlu_econometrics | 012dd1 | accuracy | gen | - | 46.49 | 61.40 | 61.40 |
| lukaemon_mmlu_econometrics | 012dd1 | f1 | gen | - | 0.46 | 0.61 | 0.61 |
| lukaemon_mmlu_high_school_psychology | 012dd1 | accuracy | gen | - | 83.49 | 87.34 | 87.52 |
| lukaemon_mmlu_high_school_psychology | 012dd1 | f1 | gen | - | 0.83 | 0.87 | 0.88 |
| lukaemon_mmlu_human_aging | 012dd1 | accuracy | gen | - | 66.82 | 71.75 | 70.85 |
| lukaemon_mmlu_human_aging | 012dd1 | f1 | gen | - | 0.67 | 0.72 | 0.71 |
| lukaemon_mmlu_us_foreign_policy | 012dd1 | accuracy | gen | - | 81.00 | 82.00 | 83.00 |
| lukaemon_mmlu_us_foreign_policy | 012dd1 | f1 | gen | - | 0.81 | 0.82 | 0.83 |
| lukaemon_mmlu_conceptual_physics | 012dd1 | accuracy | gen | - | 74.47 | 77.87 | 79.57 |
| lukaemon_mmlu_conceptual_physics | 012dd1 | f1 | gen | - | 0.74 | 0.78 | 0.80 |
