| dataset | version | metric | mode | Qwen2_5_7B |
|----- | ----- | ----- | ----- | -----|
| hellaswag | 809ef1 | accuracy | gen | 76.97 |
| hellaswag | 809ef1 | f1 | gen | 0.77 |
| math_prm800k_500-llmjudge | 6ff468 | accuracy | gen | 56.20 |
| math_prm800k_500-llmjudge | 6ff468 | f1 | gen | 0.56 |
| bbeh_boolean_expressions | ae90fc | accuracy | gen | 17.00 |
| bbeh_boolean_expressions | ae90fc | f1 | gen | 0.17 |
| bbeh_disambiguation_qa | ae90fc | accuracy | gen | 36.67 |
| bbeh_disambiguation_qa | ae90fc | f1 | gen | 0.37 |
| bbeh_geometric_shapes | ae90fc | accuracy | gen | 28.00 |
| bbeh_geometric_shapes | ae90fc | f1 | gen | 0.28 |
| bbeh_hyperbaton | ae90fc | accuracy | gen | 0.00 |
| bbeh_hyperbaton | ae90fc | f1 | gen | 0.00 |
| bbeh_movie_recommendation | ae90fc | accuracy | gen | 23.00 |
| bbeh_movie_recommendation | ae90fc | f1 | gen | 0.23 |
| bbeh_nycc | ae90fc | accuracy | gen | 9.50 |
| bbeh_nycc | ae90fc | f1 | gen | 0.10 |
| bbeh_shuffled_objects | ae90fc | accuracy | gen | 9.00 |
| bbeh_shuffled_objects | ae90fc | f1 | gen | 0.09 |
| bbeh_boardgame_qa | ae90fc | accuracy | gen | 20.00 |
| bbeh_boardgame_qa | ae90fc | f1 | gen | 0.20 |
| bbeh_buggy_tables | ae90fc | accuracy | gen | 2.00 |
| bbeh_buggy_tables | ae90fc | f1 | gen | 0.02 |
| bbeh_causal_understanding | ae90fc | accuracy | gen | 31.00 |
| bbeh_causal_understanding | ae90fc | f1 | gen | 0.31 |
| bbeh_dyck_languages | ae90fc | accuracy | gen | 1.50 |
| bbeh_dyck_languages | ae90fc | f1 | gen | 0.01 |
| bbeh_linguini | ae90fc | accuracy | gen | 5.50 |
| bbeh_linguini | ae90fc | f1 | gen | 0.06 |
| bbeh_multistep_arithmetic | ae90fc | accuracy | gen | 0.50 |
| bbeh_multistep_arithmetic | ae90fc | f1 | gen | 0.01 |
| bbeh_object_counting | ae90fc | accuracy | gen | 0.50 |
| bbeh_object_counting | ae90fc | f1 | gen | 0.01 |
| bbeh_object_properties | ae90fc | accuracy | gen | 2.50 |
| bbeh_object_properties | ae90fc | f1 | gen | 0.03 |
| bbeh_sarc_triples | ae90fc | accuracy | gen | 16.00 |
| bbeh_sarc_triples | ae90fc | f1 | gen | 0.16 |
| bbeh_spatial_reasoning | ae90fc | accuracy | gen | 1.50 |
| bbeh_spatial_reasoning | ae90fc | f1 | gen | 0.01 |
| bbeh_sportqa | ae90fc | accuracy | gen | 3.00 |
| bbeh_sportqa | ae90fc | f1 | gen | 0.03 |
| bbeh_temporal_sequence | ae90fc | accuracy | gen | 0.00 |
| bbeh_temporal_sequence | ae90fc | f1 | gen | 0.00 |
| bbeh_time_arithmetic | ae90fc | accuracy | gen | 6.00 |
| bbeh_time_arithmetic | ae90fc | f1 | gen | 0.06 |
| bbeh_web_of_lies | ae90fc | accuracy | gen | 8.50 |
| bbeh_web_of_lies | ae90fc | f1 | gen | 0.09 |
| bbeh_word_sorting | ae90fc | accuracy | gen | 3.00 |
| bbeh_word_sorting | ae90fc | f1 | gen | 0.03 |
| bbeh_zebra_puzzles | ae90fc | accuracy | gen | 2.50 |
| bbeh_zebra_puzzles | ae90fc | f1 | gen | 0.03 |
| bbh-temporal_sequences | 3f2d84 | score | gen | 48.80 |
| bbh-disambiguation_qa | 3f2d84 | score | gen | 55.20 |
| bbh-date_understanding | 3f2d84 | score | gen | 45.60 |
| bbh-tracking_shuffled_objects_three_objects | 3f2d84 | score | gen | 78.00 |
| bbh-penguins_in_a_table | 3f2d84 | score | gen | 77.40 |
| bbh-geometric_shapes | 3f2d84 | score | gen | 42.00 |
| bbh-snarks | 3f2d84 | score | gen | 59.55 |
| bbh-ruin_names | 3f2d84 | score | gen | 54.40 |
| bbh-tracking_shuffled_objects_seven_objects | 3f2d84 | score | gen | 56.40 |
| bbh-tracking_shuffled_objects_five_objects | 3f2d84 | score | gen | 64.40 |
| bbh-logical_deduction_three_objects | 3f2d84 | score | gen | 82.80 |
| bbh-hyperbaton | 3f2d84 | score | gen | 70.40 |
| bbh-logical_deduction_five_objects | 3f2d84 | score | gen | 48.40 |
| bbh-logical_deduction_seven_objects | 3f2d84 | score | gen | 41.20 |
| bbh-movie_recommendation | 3f2d84 | score | gen | 61.20 |
| bbh-salient_translation_error_detection | 3f2d84 | score | gen | 28.80 |
| bbh-reasoning_about_colored_objects | 3f2d84 | score | gen | 81.60 |
| bbh-multistep_arithmetic_two | 3f2d84 | score | gen | 79.60 |
| bbh-navigate | 3f2d84 | score | gen | 82.40 |
| bbh-dyck_languages | 3f2d84 | score | gen | 0.40 |
| bbh-word_sorting | 3f2d84 | score | gen | 34.00 |
| bbh-sports_understanding | 3f2d84 | score | gen | 68.40 |
| bbh-boolean_expressions | 3f2d84 | score | gen | 91.20 |
| bbh-object_counting | 3f2d84 | score | gen | 65.60 |
| bbh-formal_fallacies | 3f2d84 | score | gen | 59.60 |
| bbh-causal_judgement | 3f2d84 | score | gen | 55.61 |
| bbh-web_of_lies | 3f2d84 | score | gen | 69.20 |
| cmmlu-agronomy | 7c9e30 | accuracy | gen | 46.75 |
| cmmlu-agronomy | 7c9e30 | f1 | gen | 0.47 |
| cmmlu-anatomy | 84ab0f | accuracy | gen | 52.03 |
| cmmlu-anatomy | 84ab0f | f1 | gen | 0.52 |
| cmmlu-ancient_chinese | 18a73e | accuracy | gen | 32.93 |
| cmmlu-ancient_chinese | 18a73e | f1 | gen | 0.33 |
| cmmlu-arts | d496c2 | accuracy | gen | 69.38 |
| cmmlu-arts | d496c2 | f1 | gen | 0.69 |
| cmmlu-astronomy | 94a1ad | accuracy | gen | 33.33 |
| cmmlu-astronomy | 94a1ad | f1 | gen | 0.33 |
| cmmlu-business_ethics | b66299 | accuracy | gen | 43.54 |
| cmmlu-business_ethics | b66299 | f1 | gen | 0.44 |
| cmmlu-chinese_civil_service_exam | 41629d | accuracy | gen | 48.12 |
| cmmlu-chinese_civil_service_exam | 41629d | f1 | gen | 0.48 |
| cmmlu-chinese_driving_rule | 1e9d3c | accuracy | gen | 50.38 |
| cmmlu-chinese_driving_rule | 1e9d3c | f1 | gen | 0.50 |
| cmmlu-chinese_food_culture | 5fe533 | accuracy | gen | 42.65 |
| cmmlu-chinese_food_culture | 5fe533 | f1 | gen | 0.43 |
| cmmlu-chinese_foreign_policy | 50ea53 | accuracy | gen | 44.86 |
| cmmlu-chinese_foreign_policy | 50ea53 | f1 | gen | 0.45 |
| cmmlu-chinese_history | 65d9e7 | accuracy | gen | 51.70 |
| cmmlu-chinese_history | 65d9e7 | f1 | gen | 0.52 |
| cmmlu-chinese_literature | bf10c3 | accuracy | gen | 46.08 |
| cmmlu-chinese_literature | bf10c3 | f1 | gen | 0.46 |
| cmmlu-chinese_teacher_qualification | 0fc6aa | accuracy | gen | 43.02 |
| cmmlu-chinese_teacher_qualification | 0fc6aa | f1 | gen | 0.43 |
| cmmlu-clinical_knowledge | e8fd9f | accuracy | gen | 43.04 |
| cmmlu-clinical_knowledge | e8fd9f | f1 | gen | 0.43 |
| cmmlu-college_actuarial_science | c0c119 | accuracy | gen | 28.30 |
| cmmlu-college_actuarial_science | c0c119 | f1 | gen | 0.28 |
| cmmlu-college_education | a6d967 | accuracy | gen | 35.51 |
| cmmlu-college_education | a6d967 | f1 | gen | 0.36 |
| cmmlu-college_engineering_hydrology | 2fc1c4 | accuracy | gen | 33.02 |
| cmmlu-college_engineering_hydrology | 2fc1c4 | f1 | gen | 0.33 |
| cmmlu-college_law | d918f6 | accuracy | gen | 46.30 |
| cmmlu-college_law | d918f6 | f1 | gen | 0.46 |
| cmmlu-college_mathematics | b665a2 | accuracy | gen | 32.38 |
| cmmlu-college_mathematics | b665a2 | f1 | gen | 0.32 |
| cmmlu-college_medical_statistics | 2b1a51 | accuracy | gen | 35.85 |
| cmmlu-college_medical_statistics | 2b1a51 | f1 | gen | 0.36 |
| cmmlu-college_medicine | ac9e75 | accuracy | gen | 46.15 |
| cmmlu-college_medicine | ac9e75 | f1 | gen | 0.46 |
| cmmlu-computer_science | 5b63b8 | accuracy | gen | 57.35 |
| cmmlu-computer_science | 5b63b8 | f1 | gen | 0.57 |
| cmmlu-computer_security | c37854 | accuracy | gen | 56.73 |
| cmmlu-computer_security | c37854 | f1 | gen | 0.57 |
| cmmlu-conceptual_physics | e13116 | accuracy | gen | 56.46 |
| cmmlu-conceptual_physics | e13116 | f1 | gen | 0.56 |
| cmmlu-construction_project_management | 799df1 | accuracy | gen | 43.88 |
| cmmlu-construction_project_management | 799df1 | f1 | gen | 0.44 |
| cmmlu-economics | 503c58 | accuracy | gen | 55.35 |
| cmmlu-economics | 503c58 | f1 | gen | 0.55 |
| cmmlu-education | 823c96 | accuracy | gen | 41.72 |
| cmmlu-education | 823c96 | f1 | gen | 0.42 |
| cmmlu-electrical_engineering | 69c4f3 | accuracy | gen | 34.30 |
| cmmlu-electrical_engineering | 69c4f3 | f1 | gen | 0.34 |
| cmmlu-elementary_chinese | 61ed08 | accuracy | gen | 46.03 |
| cmmlu-elementary_chinese | 61ed08 | f1 | gen | 0.46 |
| cmmlu-elementary_commonsense | 3c2aa7 | accuracy | gen | 46.46 |
| cmmlu-elementary_commonsense | 3c2aa7 | f1 | gen | 0.46 |
| cmmlu-elementary_information_and_technology | 4ba53f | accuracy | gen | 58.40 |
| cmmlu-elementary_information_and_technology | 4ba53f | f1 | gen | 0.58 |
| cmmlu-elementary_mathematics | 1fe0ee | accuracy | gen | 46.52 |
| cmmlu-elementary_mathematics | 1fe0ee | f1 | gen | 0.47 |
| cmmlu-ethnology | ae0ac8 | accuracy | gen | 43.70 |
| cmmlu-ethnology | ae0ac8 | f1 | gen | 0.44 |
| cmmlu-food_science | dfb5a1 | accuracy | gen | 42.66 |
| cmmlu-food_science | dfb5a1 | f1 | gen | 0.43 |
| cmmlu-genetics | 95a0c9 | accuracy | gen | 39.77 |
| cmmlu-genetics | 95a0c9 | f1 | gen | 0.40 |
| cmmlu-global_facts | e3cf9e | accuracy | gen | 57.72 |
| cmmlu-global_facts | e3cf9e | f1 | gen | 0.58 |
| cmmlu-high_school_biology | 0811e7 | accuracy | gen | 39.64 |
| cmmlu-high_school_biology | 0811e7 | f1 | gen | 0.40 |
| cmmlu-high_school_chemistry | 342b0f | accuracy | gen | 43.94 |
| cmmlu-high_school_chemistry | 342b0f | f1 | gen | 0.44 |
| cmmlu-high_school_geography | 2a2c92 | accuracy | gen | 58.47 |
| cmmlu-high_school_geography | 2a2c92 | f1 | gen | 0.58 |
| cmmlu-high_school_mathematics | 86f22a | accuracy | gen | 51.83 |
| cmmlu-high_school_mathematics | 86f22a | f1 | gen | 0.52 |
| cmmlu-high_school_physics | d4fe4b | accuracy | gen | 56.36 |
| cmmlu-high_school_physics | d4fe4b | f1 | gen | 0.56 |
| cmmlu-high_school_politics | ded656 | accuracy | gen | 41.96 |
| cmmlu-high_school_politics | ded656 | f1 | gen | 0.42 |
| cmmlu-human_sexuality | 11cfc3 | accuracy | gen | 33.33 |
| cmmlu-human_sexuality | 11cfc3 | f1 | gen | 0.33 |
| cmmlu-international_law | 0bc7f3 | accuracy | gen | 43.78 |
| cmmlu-international_law | 0bc7f3 | f1 | gen | 0.44 |
| cmmlu-journalism | 9b0da8 | accuracy | gen | 47.09 |
| cmmlu-journalism | 9b0da8 | f1 | gen | 0.47 |
| cmmlu-jurisprudence | 63bbe5 | accuracy | gen | 51.34 |
| cmmlu-jurisprudence | 63bbe5 | f1 | gen | 0.51 |
| cmmlu-legal_and_moral_basis | 252a51 | accuracy | gen | 51.40 |
| cmmlu-legal_and_moral_basis | 252a51 | f1 | gen | 0.51 |
| cmmlu-logical | 245f3d | accuracy | gen | 59.35 |
| cmmlu-logical | 245f3d | f1 | gen | 0.59 |
| cmmlu-machine_learning | 1992ee | accuracy | gen | 45.90 |
| cmmlu-machine_learning | 1992ee | f1 | gen | 0.46 |
| cmmlu-management | 454dc0 | accuracy | gen | 50.95 |
| cmmlu-management | 454dc0 | f1 | gen | 0.51 |
| cmmlu-marketing | cb3955 | accuracy | gen | 46.67 |
| cmmlu-marketing | cb3955 | f1 | gen | 0.47 |
| cmmlu-marxist_theory | 88f9a2 | accuracy | gen | 58.73 |
| cmmlu-marxist_theory | 88f9a2 | f1 | gen | 0.59 |
| cmmlu-modern_chinese | 84adbd | accuracy | gen | 31.90 |
| cmmlu-modern_chinese | 84adbd | f1 | gen | 0.32 |
| cmmlu-nutrition | 157fb8 | accuracy | gen | 50.34 |
| cmmlu-nutrition | 157fb8 | f1 | gen | 0.50 |
| cmmlu-philosophy | cbe293 | accuracy | gen | 57.14 |
| cmmlu-philosophy | cbe293 | f1 | gen | 0.57 |
| cmmlu-professional_accounting | 1fd7d6 | accuracy | gen | 57.71 |
| cmmlu-professional_accounting | 1fd7d6 | f1 | gen | 0.58 |
| cmmlu-professional_law | b24c17 | accuracy | gen | 45.97 |
| cmmlu-professional_law | b24c17 | f1 | gen | 0.46 |
| cmmlu-professional_medicine | 8780af | accuracy | gen | 44.15 |
| cmmlu-professional_medicine | 8780af | f1 | gen | 0.44 |
| cmmlu-professional_psychology | 312211 | accuracy | gen | 44.83 |
| cmmlu-professional_psychology | 312211 | f1 | gen | 0.45 |
| cmmlu-public_relations | 108236 | accuracy | gen | 50.57 |
| cmmlu-public_relations | 108236 | f1 | gen | 0.51 |
| cmmlu-security_study | 4ae05c | accuracy | gen | 54.07 |
| cmmlu-security_study | 4ae05c | f1 | gen | 0.54 |
| cmmlu-sociology | e243f7 | accuracy | gen | 46.46 |
| cmmlu-sociology | e243f7 | f1 | gen | 0.46 |
| cmmlu-sports_science | 591cca | accuracy | gen | 43.64 |
| cmmlu-sports_science | 591cca | f1 | gen | 0.44 |
| cmmlu-traditional_chinese_medicine | 427690 | accuracy | gen | 51.35 |
| cmmlu-traditional_chinese_medicine | 427690 | f1 | gen | 0.51 |
| cmmlu-virology | 708dbd | accuracy | gen | 53.25 |
| cmmlu-virology | 708dbd | f1 | gen | 0.53 |
| cmmlu-world_history | 18602e | accuracy | gen | 55.28 |
| cmmlu-world_history | 18602e | f1 | gen | 0.55 |
| cmmlu-world_religions | a38f01 | accuracy | gen | 65.62 |
| cmmlu-world_religions | a38f01 | f1 | gen | 0.66 |
| lukaemon_mmlu_college_biology | 012dd1 | accuracy | gen | 83.33 |
| lukaemon_mmlu_college_biology | 012dd1 | f1 | gen | 0.83 |
| lukaemon_mmlu_college_chemistry | 012dd1 | accuracy | gen | 51.00 |
| lukaemon_mmlu_college_chemistry | 012dd1 | f1 | gen | 0.51 |
| lukaemon_mmlu_college_computer_science | 012dd1 | accuracy | gen | 63.00 |
| lukaemon_mmlu_college_computer_science | 012dd1 | f1 | gen | 0.63 |
| lukaemon_mmlu_college_mathematics | 012dd1 | accuracy | gen | 56.00 |
| lukaemon_mmlu_college_mathematics | 012dd1 | f1 | gen | 0.56 |
| lukaemon_mmlu_college_physics | 012dd1 | accuracy | gen | 62.75 |
| lukaemon_mmlu_college_physics | 012dd1 | f1 | gen | 0.63 |
| lukaemon_mmlu_electrical_engineering | 012dd1 | accuracy | gen | 67.59 |
| lukaemon_mmlu_electrical_engineering | 012dd1 | f1 | gen | 0.68 |
| lukaemon_mmlu_astronomy | 012dd1 | accuracy | gen | 83.55 |
| lukaemon_mmlu_astronomy | 012dd1 | f1 | gen | 0.84 |
| lukaemon_mmlu_anatomy | 012dd1 | accuracy | gen | 73.33 |
| lukaemon_mmlu_anatomy | 012dd1 | f1 | gen | 0.73 |
| lukaemon_mmlu_abstract_algebra | 012dd1 | accuracy | gen | 51.00 |
| lukaemon_mmlu_abstract_algebra | 012dd1 | f1 | gen | 0.51 |
| lukaemon_mmlu_machine_learning | 012dd1 | accuracy | gen | 52.68 |
| lukaemon_mmlu_machine_learning | 012dd1 | f1 | gen | 0.53 |
| lukaemon_mmlu_clinical_knowledge | 012dd1 | accuracy | gen | 75.09 |
| lukaemon_mmlu_clinical_knowledge | 012dd1 | f1 | gen | 0.75 |
| lukaemon_mmlu_global_facts | 012dd1 | accuracy | gen | 46.00 |
| lukaemon_mmlu_global_facts | 012dd1 | f1 | gen | 0.46 |
| lukaemon_mmlu_management | 012dd1 | accuracy | gen | 83.50 |
| lukaemon_mmlu_management | 012dd1 | f1 | gen | 0.83 |
| lukaemon_mmlu_nutrition | 012dd1 | accuracy | gen | 75.82 |
| lukaemon_mmlu_nutrition | 012dd1 | f1 | gen | 0.76 |
| lukaemon_mmlu_marketing | 012dd1 | accuracy | gen | 87.18 |
| lukaemon_mmlu_marketing | 012dd1 | f1 | gen | 0.87 |
| lukaemon_mmlu_professional_accounting | 012dd1 | accuracy | gen | 59.57 |
| lukaemon_mmlu_professional_accounting | 012dd1 | f1 | gen | 0.60 |
| lukaemon_mmlu_high_school_geography | 012dd1 | accuracy | gen | 84.85 |
| lukaemon_mmlu_high_school_geography | 012dd1 | f1 | gen | 0.85 |
| lukaemon_mmlu_international_law | 012dd1 | accuracy | gen | 72.73 |
| lukaemon_mmlu_international_law | 012dd1 | f1 | gen | 0.73 |
| lukaemon_mmlu_moral_scenarios | 012dd1 | accuracy | gen | 37.88 |
| lukaemon_mmlu_moral_scenarios | 012dd1 | f1 | gen | 0.38 |
| lukaemon_mmlu_computer_security | 012dd1 | accuracy | gen | 75.00 |
| lukaemon_mmlu_computer_security | 012dd1 | f1 | gen | 0.75 |
| lukaemon_mmlu_high_school_microeconomics | 012dd1 | accuracy | gen | 85.71 |
| lukaemon_mmlu_high_school_microeconomics | 012dd1 | f1 | gen | 0.86 |
| lukaemon_mmlu_professional_law | 012dd1 | accuracy | gen | 49.35 |
| lukaemon_mmlu_professional_law | 012dd1 | f1 | gen | 0.49 |
| lukaemon_mmlu_medical_genetics | 012dd1 | accuracy | gen | 75.00 |
| lukaemon_mmlu_medical_genetics | 012dd1 | f1 | gen | 0.75 |
| lukaemon_mmlu_professional_psychology | 012dd1 | accuracy | gen | 70.42 |
| lukaemon_mmlu_professional_psychology | 012dd1 | f1 | gen | 0.70 |
| lukaemon_mmlu_jurisprudence | 012dd1 | accuracy | gen | 75.93 |
| lukaemon_mmlu_jurisprudence | 012dd1 | f1 | gen | 0.76 |
| lukaemon_mmlu_world_religions | 012dd1 | accuracy | gen | 85.38 |
| lukaemon_mmlu_world_religions | 012dd1 | f1 | gen | 0.85 |
| lukaemon_mmlu_philosophy | 012dd1 | accuracy | gen | 70.74 |
| lukaemon_mmlu_philosophy | 012dd1 | f1 | gen | 0.71 |
| lukaemon_mmlu_virology | 012dd1 | accuracy | gen | 45.18 |
| lukaemon_mmlu_virology | 012dd1 | f1 | gen | 0.45 |
| lukaemon_mmlu_high_school_chemistry | 012dd1 | accuracy | gen | 63.55 |
| lukaemon_mmlu_high_school_chemistry | 012dd1 | f1 | gen | 0.64 |
| lukaemon_mmlu_public_relations | 012dd1 | accuracy | gen | 65.45 |
| lukaemon_mmlu_public_relations | 012dd1 | f1 | gen | 0.65 |
| lukaemon_mmlu_high_school_macroeconomics | 012dd1 | accuracy | gen | 79.23 |
| lukaemon_mmlu_high_school_macroeconomics | 012dd1 | f1 | gen | 0.79 |
| lukaemon_mmlu_human_sexuality | 012dd1 | accuracy | gen | 74.05 |
| lukaemon_mmlu_human_sexuality | 012dd1 | f1 | gen | 0.74 |
| lukaemon_mmlu_elementary_mathematics | 012dd1 | accuracy | gen | 88.89 |
| lukaemon_mmlu_elementary_mathematics | 012dd1 | f1 | gen | 0.89 |
| lukaemon_mmlu_high_school_physics | 012dd1 | accuracy | gen | 57.62 |
| lukaemon_mmlu_high_school_physics | 012dd1 | f1 | gen | 0.58 |
| lukaemon_mmlu_high_school_computer_science | 012dd1 | accuracy | gen | 85.00 |
| lukaemon_mmlu_high_school_computer_science | 012dd1 | f1 | gen | 0.85 |
| lukaemon_mmlu_high_school_european_history | 012dd1 | accuracy | gen | 77.58 |
| lukaemon_mmlu_high_school_european_history | 012dd1 | f1 | gen | 0.78 |
| lukaemon_mmlu_business_ethics | 012dd1 | accuracy | gen | 76.00 |
| lukaemon_mmlu_business_ethics | 012dd1 | f1 | gen | 0.76 |
| lukaemon_mmlu_moral_disputes | 012dd1 | accuracy | gen | 70.81 |
| lukaemon_mmlu_moral_disputes | 012dd1 | f1 | gen | 0.71 |
| lukaemon_mmlu_high_school_statistics | 012dd1 | accuracy | gen | 73.15 |
| lukaemon_mmlu_high_school_statistics | 012dd1 | f1 | gen | 0.73 |
| lukaemon_mmlu_miscellaneous | 012dd1 | accuracy | gen | 85.70 |
| lukaemon_mmlu_miscellaneous | 012dd1 | f1 | gen | 0.86 |
| lukaemon_mmlu_formal_logic | 012dd1 | accuracy | gen | 50.79 |
| lukaemon_mmlu_formal_logic | 012dd1 | f1 | gen | 0.51 |
| lukaemon_mmlu_high_school_government_and_politics | 012dd1 | accuracy | gen | 89.12 |
| lukaemon_mmlu_high_school_government_and_politics | 012dd1 | f1 | gen | 0.89 |
| lukaemon_mmlu_prehistory | 012dd1 | accuracy | gen | 76.23 |
| lukaemon_mmlu_prehistory | 012dd1 | f1 | gen | 0.76 |
| lukaemon_mmlu_security_studies | 012dd1 | accuracy | gen | 71.43 |
| lukaemon_mmlu_security_studies | 012dd1 | f1 | gen | 0.71 |
| lukaemon_mmlu_high_school_biology | 012dd1 | accuracy | gen | 81.94 |
| lukaemon_mmlu_high_school_biology | 012dd1 | f1 | gen | 0.82 |
| lukaemon_mmlu_logical_fallacies | 012dd1 | accuracy | gen | 78.53 |
| lukaemon_mmlu_logical_fallacies | 012dd1 | f1 | gen | 0.79 |
| lukaemon_mmlu_high_school_world_history | 012dd1 | accuracy | gen | 79.75 |
| lukaemon_mmlu_high_school_world_history | 012dd1 | f1 | gen | 0.80 |
| lukaemon_mmlu_professional_medicine | 012dd1 | accuracy | gen | 77.57 |
| lukaemon_mmlu_professional_medicine | 012dd1 | f1 | gen | 0.78 |
| lukaemon_mmlu_high_school_mathematics | 012dd1 | accuracy | gen | 67.04 |
| lukaemon_mmlu_high_school_mathematics | 012dd1 | f1 | gen | 0.67 |
| lukaemon_mmlu_college_medicine | 012dd1 | accuracy | gen | 64.16 |
| lukaemon_mmlu_college_medicine | 012dd1 | f1 | gen | 0.64 |
| lukaemon_mmlu_high_school_us_history | 012dd1 | accuracy | gen | 80.88 |
| lukaemon_mmlu_high_school_us_history | 012dd1 | f1 | gen | 0.81 |
| lukaemon_mmlu_sociology | 012dd1 | accuracy | gen | 80.60 |
| lukaemon_mmlu_sociology | 012dd1 | f1 | gen | 0.81 |
| lukaemon_mmlu_econometrics | 012dd1 | accuracy | gen | 57.02 |
| lukaemon_mmlu_econometrics | 012dd1 | f1 | gen | 0.57 |
| lukaemon_mmlu_high_school_psychology | 012dd1 | accuracy | gen | 86.79 |
| lukaemon_mmlu_high_school_psychology | 012dd1 | f1 | gen | 0.87 |
| lukaemon_mmlu_human_aging | 012dd1 | accuracy | gen | 70.40 |
| lukaemon_mmlu_human_aging | 012dd1 | f1 | gen | 0.70 |
| lukaemon_mmlu_us_foreign_policy | 012dd1 | accuracy | gen | 85.00 |
| lukaemon_mmlu_us_foreign_policy | 012dd1 | f1 | gen | 0.85 |
| lukaemon_mmlu_conceptual_physics | 012dd1 | accuracy | gen | 74.89 |
| lukaemon_mmlu_conceptual_physics | 012dd1 | f1 | gen | 0.75 |
